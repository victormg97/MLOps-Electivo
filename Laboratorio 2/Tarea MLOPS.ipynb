{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5323015e",
   "metadata": {},
   "source": [
    "`GridSearchCV` es una herramienta poderosa proporcionada por la biblioteca Scikit-learn en Python, diseñada para automatizar el proceso de ajuste de hiperparámetros de un modelo. Esta herramienta permite a los usuarios especificar un conjunto de valores potenciales para los distintos hiperparámetros de un modelo y evaluar todas las combinaciones posibles para encontrar la configuración que produce los mejores resultados de acuerdo con una métrica de evaluación especificada.\n",
    "\n",
    "### Funcionamiento de GridSearchCV\n",
    "\n",
    "**1. Definición de la cuadrícula de parámetros:**\n",
    "   - Se define un \"grid\" de hiperparámetros, que es básicamente un diccionario donde las claves son los nombres de los hiperparámetros y los valores son las listas de valores que se desean explorar para cada hiperparámetro.\n",
    "\n",
    "**2. Configuración del modelo:**\n",
    "   - Se selecciona el modelo de machine learning que se desea ajustar.\n",
    "\n",
    "**3. Evaluación cruzada:**\n",
    "   - `GridSearchCV` implementa una técnica de validación cruzada para evaluar cada combinación de hiperparámetros. Esto significa que para cada conjunto de hiperparámetros, el modelo se entrena varias veces en diferentes subconjuntos del conjunto de datos de entrenamiento.\n",
    "\n",
    "**4. Selección del mejor modelo:**\n",
    "   - Después de probar todas las combinaciones posibles, `GridSearchCV` selecciona la combinación de hiperparámetros que resulta en el mejor rendimiento del modelo según una métrica específica (como precisión, recall, F1-score, etc.).\n",
    "\n",
    "### Beneficios de usar GridSearchCV\n",
    "\n",
    "- **Automatización y simplificación**: Automatiza un proceso que de otra manera sería tedioso y propenso a errores, simplificando la búsqueda de la mejor configuración de hiperparámetros.\n",
    "- **Robustez**: Al utilizar la validación cruzada, GridSearchCV asegura que el rendimiento del modelo es evaluado de manera más robusta y menos susceptible a las fluctuaciones del conjunto de datos de entrenamiento.\n",
    "- **Mejor rendimiento**: Al explorar sistemáticamente múltiples combinaciones, se incrementa la probabilidad de encontrar una configuración de hiperparámetros que resulte en un mejor rendimiento del modelo.\n",
    "\n",
    "### Ejemplo de uso de GridSearchCV\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aae9574f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros: {'max_depth': 30, 'n_estimators': 50}\n",
      "Mejor puntuación: 0.9085263480392157\n"
     ]
    }
   ],
   "source": [
    "# Paso 1: Importar las bibliotecas necesarias\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Paso 2: Cargar los datos\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
    "data = pd.read_csv(url, sep=';')\n",
    "\n",
    "# Paso 3: Preparar los datos\n",
    "X = data.drop('quality', axis=1)  # características\n",
    "y = data['quality'] > 6  # objetivo, convertido en problema binario\n",
    "\n",
    "# Paso 4: Dividir los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Paso 5: Escalar las características (opcional, dependiendo del modelo)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Paso 6: Configurar GridSearchCV\n",
    "param_grid = {'n_estimators': [50, 100, 200], 'max_depth': [10, 20, 30]}\n",
    "grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5)\n",
    "\n",
    "# Paso 7: Entrenar con GridSearchCV\n",
    "grid_search.fit(X_train_scaled, y_train)  # Asegúrate de usar X_train_scaled si aplicaste escalado\n",
    "\n",
    "# Paso 8: Imprimir los mejores parámetros y la mejor puntuación\n",
    "print(\"Mejores parámetros:\", grid_search.best_params_)\n",
    "print(\"Mejor puntuación:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70def031",
   "metadata": {},
   "source": [
    "### Lo mismo para: \n",
    "\n",
    "# from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc41a64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros: {'learning_rate': 0.1, 'n_estimators': 200}\n",
      "Mejor puntuación: 0.8897702205882354\n"
     ]
    }
   ],
   "source": [
    "# Paso 1: Importar las bibliotecas necesarias\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Paso 2: Cargar los datos\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
    "data = pd.read_csv(url, sep=';')\n",
    "\n",
    "# Paso 3: Preparar los datos\n",
    "X = data.drop('quality', axis=1)  # características\n",
    "y = data['quality'] > 6  # objetivo, convertido en problema binario\n",
    "\n",
    "# Paso 4: Dividir los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Paso 5: Escalar las características (opcional, dependiendo del modelo)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Paso 6: Configurar GridSearchCV\n",
    "param_grid = {'n_estimators': [50, 100, 200], 'learning_rate': [0.1, 0.5, 1.0]}\n",
    "# grid_search = GridSearchCV(AdaBoostClassifier(), param_grid, cv=5)\n",
    "# Se agrega que se utiliza el algoritmo SAMME porque SAMME.R está obsoleto\n",
    "grid_search = GridSearchCV(AdaBoostClassifier(algorithm='SAMME'), param_grid, cv=5)\n",
    "\n",
    "\n",
    "# Paso 7: Entrenar con GridSearchCV\n",
    "grid_search.fit(X_train_scaled, y_train)  # Asegúrate de usar X_train_scaled si aplicaste escalado\n",
    "\n",
    "# Paso 8: Imprimir los mejores parámetros y la mejor puntuación\n",
    "print(\"Mejores parámetros:\", grid_search.best_params_)\n",
    "print(\"Mejor puntuación:\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb150bae",
   "metadata": {},
   "source": [
    "Con AdaBoostClassifier se obtiene una tasa de aprendizaje baja (learning_rate=0.1) con un mayor número de estimadores (n_estimators=200) lo cuál fue óptima en este caso."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
